{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nervous-subscriber",
   "metadata": {},
   "source": [
    "# Performing K-Means clustering on Fish Market dataset with K = 7 (No. of fish species). Normalize dataset before clustering. Scikit Learn is used for clustering. Collecting the best possible  combination and assignment in clusters and performance comparison with the true class labels (Species)? Describing results.\n",
    "\n",
    "# Reading data and displaying, As in K-means clustering we do not provide labels (unsupervised) we may not to convert our  data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "marine-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "civilian-guarantee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "73    Perch    32.0     12.5     13.7     14.7   3.5280  1.9992\n",
      "96    Perch   225.0     22.0     24.0     25.5   7.2930  3.7230\n",
      "76    Perch    70.0     15.7     17.4     18.5   4.5880  2.9415\n",
      "13    Bream   340.0     29.5     32.0     37.3  13.9129  5.0728\n",
      "87    Perch   120.0     20.0     22.0     23.5   5.6400  3.5250\n",
      "132    Pike   430.0     35.5     38.0     40.5   7.2900  4.5765\n",
      "105   Perch   250.0     25.4     27.5     28.9   7.2828  4.5662\n",
      "125   Perch  1100.0     40.1     43.0     45.5  12.5125  7.4165\n",
      "45    Roach   160.0     20.5     22.5     25.3   7.0334  3.8203\n",
      "7     Bream   390.0     27.6     30.0     35.0  12.6700  4.6900\n"
     ]
    }
   ],
   "source": [
    "current_path2 = os.getcwd()#% Finding current directory of the notebook\n",
    "current_path2 =os.path.join(current_path2,'Fish.csv') # Adding file name at the end of the address\n",
    "data2 = pd.read_csv(current_path2)# reading csv file given on current_path\n",
    "fish2 = data2.copy()\n",
    "print(fish2.sample(10))#Displaying 10 random samples from dataset\n",
    "\n",
    "\n",
    "xtrain2 =fish2.copy()\n",
    "\n",
    "xtrain2.drop(['Species'],axis=1,inplace=True) #Removing Species Column\n",
    "ytrain2 = fish2['Species']\n",
    "X_scaled = preprocessing.scale(xtrain2) # scaling so that mean =0 variance =1\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(X_scaled) # make 7 clusters and fit on normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hungry-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters= kmeans.predict(X_scaled) # Find the class of particular sample it belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "demonstrated-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ground truth label encoding \n",
    "y = [];\n",
    "Species = {'Bream':0,'Roach':1, 'Whitefish':2, 'Parkki':3 , 'Perch' : 4 , 'Pike':5 , 'Smelt':6 }\n",
    "for Specie in ytrain2:\n",
    "    y.append(Species[Specie])\n",
    "y=np.asarray(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "later-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swaping true label as per clusters \n",
    "\n",
    "from scipy.stats import mode\n",
    "k_label = np.zeros_like(clusters)\n",
    "for i in range(7):\n",
    "    tempmask = (clusters == i) # return true and false with true where cluster is equal to i-th label\n",
    "    \n",
    "    k_label[tempmask] = mode(y[tempmask])[0] # It will return value which is the most occuring in \n",
    "                                            # the given array "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-currency",
   "metadata": {},
   "source": [
    "# It can be seen from the below two arrays that the above process is just swapping clusters class labels to get the maximum accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boring-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 2 2 2 2 2 2 2 3 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 4 2 2 3 3 1 1 1 1 1 1 0 0 0 3 3\n",
      " 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 4 4\n",
      " 2 4 4 4 4 2 4 2 2 2 2 2 2 2 2 2 2 0 6 6 6 6 6 6 6 6 6 6 6 5 5 5 5 5 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affecting-miracle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 4 4 4 4 4 4 6 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 6 6 4 4 4 4 4 4 4 4 4 6 6\n",
      " 6 6 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0\n",
      " 4 0 0 0 0 4 0 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(k_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-archives",
   "metadata": {},
   "source": [
    "# How well do the clusters that you obtained in K-means clustering compare to the true class labels (Species)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "willing-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6226415094339622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y, k_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set()\n",
    "mat = confusion_matrix(y, k_label)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=Species,\n",
    "            yticklabels=Species)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-minutes",
   "metadata": {},
   "source": [
    "# Describing Results\n",
    "\n",
    "The dataset is highly imbalnced, there are only $6$ examples for the specie of \"Whitefish\". For the first class, Bream, there are $35$ samples in total out of which $25$ are classified as Bream and rest of them are classfied as Perch. \n",
    "The maximum error in classification is in case of Roach, Whitefish, and Parkki. Most of them are classified as perch. The possible reason of this failure is data distribution. More than one third of the dataset is consist of Perch, a possible reason of failure in classifying the other classes with small number of samples. The other reason of this miscalssifcation can be the close resembalnce of features in between Perch and rest of the three classes.\n",
    "\n",
    "For Pike and Smelt even thoguh we don't have many sampels the results are promising indicating that features describing these two species are more discrete when compared to other fish species. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
